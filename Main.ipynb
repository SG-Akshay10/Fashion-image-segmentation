{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201c9033",
   "metadata": {},
   "source": [
    "# Fashion Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f9f73",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74886f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e017bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_train_path = \"annotations/instances_train2024.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_train_path, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093aa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"info\" key\n",
    "data.pop(\"info\", None)\n",
    "\n",
    "# Convert \"categories\" to a DataFrame\n",
    "categories = pd.DataFrame(data[\"categories\"])\n",
    "\n",
    "# Convert \"annotations\" to a DataFrame\n",
    "annotations = pd.DataFrame(data[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7663eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ecdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the data loaded into a DataFrame called 'annotations'\n",
    "all_image_ids = annotations['image_id'].unique()  # Get a list of all unique image IDs\n",
    "\n",
    "# Select a random sample of 1000 image IDs\n",
    "sample_image_ids = random.sample(list(all_image_ids), 500)\n",
    "\n",
    "# Create a new DataFrame with the sampled annotations\n",
    "sampled_annotations = annotations[annotations['image_id'].isin(sample_image_ids)]\n",
    "\n",
    "# Get all unique image IDs in the sampled dataset\n",
    "sampled_image_ids = sampled_annotations['image_id'].unique()\n",
    "\n",
    "# Create a new DataFrame with all annotations for the sampled image IDs\n",
    "final_sampled_annotations = annotations[annotations['image_id'].isin(sampled_image_ids)]\n",
    "\n",
    "unique_categories = final_sampled_annotations['category_id'].unique()\n",
    "category_mapping = {cat: idx for idx, cat in enumerate(unique_categories)}\n",
    "final_sampled_annotations['remapped_category_id'] = final_sampled_annotations['category_id'].map(category_mapping)\n",
    "\n",
    "print(f\"Number of sampled annotations: {len(final_sampled_annotations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93250f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = final_sampled_annotations.to_json(orient='records')\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open('json_annotations.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_annotations = pd.read_json('json_annotations.json')\n",
    "sampled_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92359f01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the number of items in each category\n",
    "category_counts = sampled_annotations['category_id'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_counts.plot(kind='bar')\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Number of Items per Category')\n",
    "plt.xlabel('Category ID')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Annotate each bar with its count\n",
    "for index, value in enumerate(category_counts):\n",
    "    plt.text(index, value + 1, str(value), ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ebff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert category_id to categorical data type\n",
    "final_sampled_annotations['category_id'] = final_sampled_annotations['category_id'].astype('category')\n",
    "final_sampled_annotations\n",
    "\n",
    "# Get the category counts across the entire dataset\n",
    "category_counts = final_sampled_annotations['category_id'].value_counts()\n",
    "\n",
    "# Filter out categories with fewer than 50 images\n",
    "valid_categories = category_counts[category_counts >= 50].index\n",
    "\n",
    "# Filter the dataset to include only valid categories\n",
    "filtered_dataset = final_sampled_annotations[final_sampled_annotations['category_id'].isin(valid_categories)]\n",
    "\n",
    "unique_remapped_id = filtered_dataset['remapped_category_id'].unique()\n",
    "\n",
    "# Display total number of unique categories\n",
    "unique_categories_count = len(filtered_dataset['category_id'].unique())\n",
    "print(f\"Total number of unique categories with 50 or more images: {unique_categories_count}\")\n",
    "\n",
    "# Split the filtered dataset into train, val, and test sets\n",
    "train_val_data, test_data = train_test_split(filtered_dataset, test_size=0.1, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique rows in each dataframe based on \"image_id\"\n",
    "unique_rows_train = train_data['image_id'].nunique()\n",
    "unique_rows_val = val_data['image_id'].nunique()\n",
    "unique_rows_test = test_data['image_id'].nunique()\n",
    "\n",
    "print(f\"Unique rows in train set based on image_id: {unique_rows_train}\")\n",
    "print(f\"Unique rows in validation set based on image_id: {unique_rows_val}\")\n",
    "print(f\"Unique rows in test set based on image_id: {unique_rows_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cef444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Specify the original folder containing all images\n",
    "original_folder = 'images/train/'\n",
    "\n",
    "# Specify the new folder location for the main dataset\n",
    "main_dataset_folder = 'main_dataset'\n",
    "\n",
    "# Remove the main dataset folder if it exists to wipe out previous data\n",
    "if os.path.exists(main_dataset_folder):\n",
    "    shutil.rmtree(main_dataset_folder)\n",
    "\n",
    "# Create the main dataset folder\n",
    "os.makedirs(main_dataset_folder)\n",
    "\n",
    "# Create the main dataset folder if it doesn't exist\n",
    "os.makedirs(main_dataset_folder, exist_ok=True)\n",
    "\n",
    "# Create subfolders for train, val, and test sets\n",
    "train_folder = os.path.join(main_dataset_folder, 'train')\n",
    "val_folder = os.path.join(main_dataset_folder, 'val')\n",
    "test_folder = os.path.join(main_dataset_folder, 'test')\n",
    "\n",
    "# Create subfolders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Copy images to the respective subfolders\n",
    "for df, folder in zip([train_data, val_data, test_data], [train_folder, val_folder, test_folder]):\n",
    "    for image_id in df['image_id'].unique():\n",
    "        src_path = os.path.join(original_folder, f\"{image_id}.jpg\")  # Assuming images have .jpg extension\n",
    "        if os.path.isfile(src_path):\n",
    "            dst_path = os.path.join(folder, f\"{image_id}.jpg\")\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"Image not found: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883877a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Load the sampled annotations\n",
    "sampled_annotations = pd.read_json('json_annotations.json')\n",
    "\n",
    "# Path to the split dataset folders\n",
    "train_folder = 'main_dataset/train'\n",
    "val_folder = 'main_dataset/val'\n",
    "test_folder = 'main_dataset/test'\n",
    "\n",
    "# Path to save the YOLO-formatted data\n",
    "yolo_data_path = 'yolo_data'\n",
    "\n",
    "# Remove the yolo_data folder if it exists\n",
    "if os.path.exists(yolo_data_path):\n",
    "    shutil.rmtree(yolo_data_path)\n",
    "\n",
    "os.makedirs(yolo_data_path, exist_ok=True)\n",
    "\n",
    "# Create separate folders for images and labels\n",
    "for folder in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(yolo_data_path, folder, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(yolo_data_path, folder, 'labels'), exist_ok=True)\n",
    "\n",
    "# Function to convert annotations to YOLO format\n",
    "def convert_to_yolo_format(annotations, image_width, image_height):\n",
    "    yolo_annotations = []\n",
    "    for annotation in annotations:\n",
    "        category_id = annotation['category_id']\n",
    "        bbox = annotation['bbox']\n",
    "        x_center = (bbox[0] + bbox[2] / 2) / image_width\n",
    "        y_center = (bbox[1] + bbox[3] / 2) / image_height\n",
    "        width = bbox[2] / image_width\n",
    "        height = bbox[3] / image_height\n",
    "        yolo_annotations.append(f\"{category_id} {x_center} {y_center} {width} {height}\")\n",
    "    return yolo_annotations\n",
    "\n",
    "# Function to process each dataset folder\n",
    "def process_folder(folder_name, dataset_folder):\n",
    "    for image_id in tqdm(os.listdir(dataset_folder), desc=f\"Processing {folder_name}\"):\n",
    "        image_path = os.path.join(dataset_folder, image_id)\n",
    "        if os.path.isfile(image_path):\n",
    "            # Copy the image to the YOLO data folder\n",
    "            shutil.copy(image_path, os.path.join(yolo_data_path, folder_name, 'images', image_id))\n",
    "\n",
    "            # Get the image annotations from the sampled annotations\n",
    "            image_annotations = sampled_annotations[sampled_annotations['image_id'] == int(image_id.split('.')[0])]\n",
    "\n",
    "            if len(image_annotations) > 0:\n",
    "                # Get the image dimensions\n",
    "                image = Image.open(image_path)\n",
    "                image_width, image_height = image.size\n",
    "\n",
    "                # Convert annotations to YOLO format\n",
    "                yolo_annotations = convert_to_yolo_format(image_annotations.to_dict('records'), image_width, image_height)\n",
    "\n",
    "                # Save the YOLO annotations to a text file\n",
    "                with open(os.path.join(yolo_data_path, folder_name, 'labels', image_id.split('.')[0] + '.txt'), 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_annotations))\n",
    "\n",
    "# Process each dataset folder\n",
    "process_folder('train', train_folder)\n",
    "process_folder('val', val_folder)\n",
    "process_folder('test', test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6daa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the dataset folder\n",
    "dataset_path = f'{home}/yolo_data'\n",
    "\n",
    "# Get the number of classes from the annotations\n",
    "num_classes = unique_categories_count\n",
    "\n",
    "# Get the class names from the categories dataframe\n",
    "class_names = filtered_dataset['category_id'].unique().tolist()\n",
    "\n",
    "# Create the data.yml content\n",
    "data_yml_content = f\"\"\"\\\n",
    "# Data path\n",
    "path: ./{dataset_path}\n",
    "\n",
    "# Train and validation data as 1) dict or 2) list of dict\n",
    "train: ../{dataset_path}/train/images\n",
    "val: ../{dataset_path}/val/images\n",
    "\n",
    "# Classes\n",
    "nc: 15\n",
    "names: {unique_remapped_id}\n",
    "\"\"\"\n",
    "\n",
    "# Save the data.yml file\n",
    "with open('data.yaml', 'w', encoding='utf-8') as f:\n",
    "    f.write(data_yml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov9/train.py \\\n",
    "--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
    "--data data.yaml \\\n",
    "--weights {home}/weights/gelan-c.pt \\\n",
    "--cfg yolov9/models/detect/gelan-c.yaml \\\n",
    "--hyp hyp.scratch-high.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f099a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
